#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¼˜åŒ–èåˆæƒé‡
"""
import os
import sys
import time
import pickle
import numpy as np
import networkx as nx
from sklearn.linear_model import LogisticRegression

# æ·»åŠ è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from GraphEmbedding.ge.classify import read_node_label, Classifier
from algorithms.traditional.struc2vec import Struc2Vec

def fuse_with_alpha(dist1_path, dist2_path, alpha):
    """ä½¿ç”¨æŒ‡å®šæƒé‡èåˆè·ç¦»"""
    with open(dist1_path, 'rb') as f:
        dist1 = pickle.load(f)
    with open(dist2_path, 'rb') as f:
        dist2 = pickle.load(f)
    
    fused = {}
    for pair in set(dist1.keys()).intersection(dist2.keys()):
        fused[pair] = {}
        layers1 = dist1[pair]
        layers2 = dist2[pair]
        for layer in set(layers1.keys()).intersection(layers2.keys()):
            fused[pair][layer] = alpha * layers1[layer] + (1 - alpha) * layers2[layer]
    
    return fused

def evaluate_fusion_alpha(G, X, Y, dist1_path, dist2_path, alpha):
    """è¯„ä¼°ç‰¹å®šæƒé‡çš„èåˆæ•ˆæœ"""
    try:
        # ç”Ÿæˆèåˆè·ç¦»
        fused_dist = fuse_with_alpha(dist1_path, dist2_path, alpha)
        
        # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
        temp_path = f"temp_fused_{alpha:.3f}.pkl"
        with open(temp_path, 'wb') as f:
            pickle.dump(fused_dist, f)
        
        # è®­ç»ƒæ¨¡å‹
        model = Struc2Vec(G, walk_length=40, num_walks=6, workers=1, verbose=0,
                         opt1_reduce_len=True, opt2_reduce_sim_calc=True,
                         structural_dist_file=temp_path)
        model.train(embed_size=64, window_size=5, workers=1, iter=2)
        embeddings = model.get_embeddings()
        
        # è¯„ä¼°
        clf = Classifier(embeddings=embeddings, clf=LogisticRegression(max_iter=1000))
        metrics = clf.split_train_evaluate(X, Y, 0.8)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.remove(temp_path)
        
        return metrics['acc']
        
    except Exception as e:
        print(f"   âŒ Î±={alpha:.3f} å¤±è´¥: {e}")
        return 0.0

def grid_search_alpha():
    """ç½‘æ ¼æœç´¢æœ€ä½³æƒé‡"""
    print("=" * 80)
    print("èåˆæƒé‡ä¼˜åŒ–")
    print("=" * 80)
    
    # è®¾ç½®è·¯å¾„
    base_dir = os.path.dirname(os.path.abspath(__file__))
    graph_path = os.path.join(base_dir, "data/flight/brazil-airports.edgelist")
    label_path = os.path.join(base_dir, "data/flight/labels-brazil-airports.txt")
    output_dir = os.path.join(base_dir, "output")
    
    original_dist = os.path.join(output_dir, "structural_dist_original.pkl")
    graphlet_dist = os.path.join(output_dir, "structural_dist_brazil-airports.pkl")
    
    # åŠ è½½æ•°æ®
    print("\nåŠ è½½æ•°æ®...")
    G = nx.read_edgelist(graph_path, nodetype=str, create_using=nx.DiGraph())
    X, Y = read_node_label(label_path, skip_head=True)
    
    print(f"å›¾ä¿¡æ¯: {G.number_of_nodes()} èŠ‚ç‚¹, {G.number_of_edges()} è¾¹")
    print(f"æ ‡ç­¾ä¿¡æ¯: {len(X)} ä¸ªæ ‡è®°èŠ‚ç‚¹")
    
    # æƒé‡å€™é€‰å€¼
    alphas = np.arange(0.0, 1.1, 0.1)  # 0.0 åˆ° 1.0ï¼Œæ­¥é•¿ 0.1
    
    print(f"\nå¼€å§‹æƒé‡æœç´¢...")
    print(f"æœç´¢èŒƒå›´: Î± âˆˆ [0.0, 1.0]ï¼Œæ­¥é•¿ 0.1")
    print(f"Î±=0.0: çº¯ Graphletï¼ŒÎ±=1.0: çº¯åº¦åºåˆ—")
    
    results = {}
    best_alpha = 0.0
    best_acc = 0.0
    
    for alpha in alphas:
        print(f"\næµ‹è¯• Î±={alpha:.1f}...")
        start = time.time()
        
        acc = evaluate_fusion_alpha(G, X, Y, original_dist, graphlet_dist, alpha)
        elapsed = time.time() - start
        
        results[alpha] = {
            'accuracy': acc,
            'time': elapsed
        }
        
        print(f"   å‡†ç¡®ç‡: {acc:.4f}, è€—æ—¶: {elapsed:.2f}s")
        
        if acc > best_acc:
            best_acc = acc
            best_alpha = alpha
            print(f"   ğŸ¯ æ–°çš„æœ€ä½³æƒé‡!")
    
    # æ‰“å°ç»“æœ
    print("\n" + "=" * 80)
    print("æƒé‡ä¼˜åŒ–ç»“æœ")
    print("=" * 80)
    
    print(f"\n{'æƒé‡ Î±':<10} {'å‡†ç¡®ç‡':<10} {'æ—¶é—´(s)':<10} {'è¯´æ˜':<20}")
    print("-" * 55)
    
    for alpha in sorted(results.keys()):
        data = results[alpha]
        marker = "ğŸ†" if alpha == best_alpha else "  "
        desc = get_alpha_description(alpha)
        print(f"{marker} {alpha:<8.1f} {data['accuracy']:<10.4f} {data['time']:<10.2f} {desc}")
    
    print(f"\nğŸ¯ æœ€ä½³æƒé‡: Î± = {best_alpha:.1f}")
    print(f"ğŸ¯ æœ€ä½³å‡†ç¡®ç‡: {best_acc:.4f}")
    
    # ä¿å­˜æœ€ä½³èåˆæ–‡ä»¶
    print(f"\nä¿å­˜æœ€ä½³èåˆæ–‡ä»¶...")
    best_fused = fuse_with_alpha(original_dist, graphlet_dist, best_alpha)
    best_path = os.path.join(output_dir, f"fused_optimal_alpha_{best_alpha:.1f}.pkl")
    with open(best_path, 'wb') as f:
        pickle.dump(best_fused, f)
    print(f"âœ… æœ€ä½³èåˆæ–‡ä»¶: {best_path}")
    
    # åˆ†æè¶‹åŠ¿
    print(f"\nğŸ“ˆ è¶‹åŠ¿åˆ†æ:")
    accuracies = [results[alpha]['accuracy'] for alpha in sorted(results.keys())]
    
    print(f"  çº¯ Graphlet (Î±=0.0): {results[0.0]['accuracy']:.4f}")
    print(f"  å‡è¡¡èåˆ (Î±=0.5): {results[0.5]['accuracy']:.4f}")
    print(f"  çº¯åº¦åºåˆ— (Î±=1.0): {results[1.0]['accuracy']:.4f}")
    
    # å¯»æ‰¾è¶‹åŠ¿
    max_idx = accuracies.index(max(accuracies))
    optimal_range = f"Î± âˆˆ [{max(0, (max_idx-1)*0.1):.1f}, {min(1.0, (max_idx+1)*0.1):.1f}]"
    print(f"  æœ€ä¼˜åŒºé—´: {optimal_range}")
    
    return results, best_alpha, best_acc

def get_alpha_description(alpha):
    """è·å–æƒé‡çš„æè¿°"""
    if alpha == 0.0:
        return "çº¯ Graphlet"
    elif alpha == 1.0:
        return "çº¯åº¦åºåˆ—"
    elif alpha == 0.5:
        return "å‡è¡¡èåˆ"
    elif alpha < 0.5:
        return "Graphlet ä¸ºä¸»"
    else:
        return "åº¦åºåˆ—ä¸ºä¸»"

def fine_search(best_alpha, results):
    """åœ¨æœ€ä½³æƒé‡é™„è¿‘è¿›è¡Œç²¾ç»†æœç´¢"""
    print(f"\n" + "=" * 60)
    print(f"ç²¾ç»†æœç´¢ (Î± = {best_alpha:.1f} Â± 0.1)")
    print("=" * 60)
    
    # åœ¨æœ€ä½³æƒé‡é™„è¿‘æœç´¢
    fine_alphas = np.arange(max(0, best_alpha-0.1), min(1.1, best_alpha+0.15), 0.02)
    
    base_dir = os.path.dirname(os.path.abspath(__file__))
    graph_path = os.path.join(base_dir, "data/flight/brazil-airports.edgelist")
    label_path = os.path.join(base_dir, "data/flight/labels-brazil-airports.txt")
    output_dir = os.path.join(base_dir, "output")
    
    original_dist = os.path.join(output_dir, "structural_dist_original.pkl")
    graphlet_dist = os.path.join(output_dir, "structural_dist_brazil-airports.pkl")
    
    G = nx.read_edgelist(graph_path, nodetype=str, create_using=nx.DiGraph())
    X, Y = read_node_label(label_path, skip_head=True)
    
    fine_best_alpha = best_alpha
    fine_best_acc = results[best_alpha]['accuracy']
    
    print(f"æœç´¢èŒƒå›´: {fine_alphas[0]:.2f} åˆ° {fine_alphas[-1]:.2f}ï¼Œæ­¥é•¿ 0.02")
    
    for alpha in fine_alphas:
        if alpha in results:  # è·³è¿‡å·²ç»æµ‹è¯•è¿‡çš„
            continue
            
        print(f"ç²¾ç»†æµ‹è¯• Î±={alpha:.2f}...")
        acc = evaluate_fusion_alpha(G, X, Y, original_dist, graphlet_dist, alpha)
        
        if acc > fine_best_acc:
            fine_best_acc = acc
            fine_best_alpha = alpha
            print(f"   ğŸ¯ ç²¾ç»†æœç´¢æ–°æœ€ä½³: Î±={alpha:.2f}, å‡†ç¡®ç‡={acc:.4f}")
    
    return fine_best_alpha, fine_best_acc

if __name__ == "__main__":
    try:
        # ç²—æœç´¢
        results, best_alpha, best_acc = grid_search_alpha()
        
        # ç²¾ç»†æœç´¢
        fine_alpha, fine_acc = fine_search(best_alpha, results)
        
        print(f"\n" + "=" * 80)
        print("æœ€ç»ˆä¼˜åŒ–ç»“æœ")
        print("=" * 80)
        print(f"ğŸ† æœ€ç»ˆæœ€ä½³æƒé‡: Î± = {fine_alpha:.2f}")
        print(f"ğŸ† æœ€ç»ˆæœ€ä½³å‡†ç¡®ç‡: {fine_acc:.4f}")
        
        # ä¸åŸºå‡†æ¯”è¾ƒ
        baseline_acc = 0.6429  # åŸå§‹æ–¹æ³•çš„å¤§è‡´å‡†ç¡®ç‡
        improvement = (fine_acc - baseline_acc) / baseline_acc * 100
        print(f"ğŸ“ˆ ç›¸å¯¹åŸå§‹æ–¹æ³•æ”¹è¿›: {improvement:+.1f}%")
        
        print(f"\nğŸ’¡ å»ºè®®:")
        print(f"  1. ä½¿ç”¨æƒé‡ Î± = {fine_alpha:.2f} è¿›è¡Œèåˆ")
        print(f"  2. åœ¨å…¶ä»–æ•°æ®é›†ä¸ŠéªŒè¯è¿™ä¸ªæƒé‡")
        print(f"  3. è€ƒè™‘è‡ªé€‚åº”æƒé‡ç­–ç•¥")
        
    except Exception as e:
        print(f"\nâŒ å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()