#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®‰å…¨çš„é«˜çº§èåˆæ–¹æ³•æ¯”è¾ƒè„šæœ¬
ä¸¥æ ¼é˜²æ­¢æ•°æ®æ³„éœ²çš„ç‰ˆæœ¬
"""
import sys
import os
import time
import argparse
import networkx as nx
from pathlib import Path

# æ·»åŠ çˆ¶é¡¹ç›®è·¯å¾„
parent_path = Path(__file__).parent.parent
sys.path.append(str(parent_path))

from GraphEmbedding.ge.classify import read_node_label
from algorithms.traditional.struc2vec import Struc2Vec
from src.algorithms.advanced_fusion_methods import AdvancedFusionStruc2Vec
from safe_evaluation import safe_evaluate_method, DataLeakageChecker

def load_dataset(dataset_name):
    """åŠ è½½æ•°æ®é›†"""
    data_base = parent_path / 'data'
    
    datasets = {
        'brazil-airports': {
            'graph': data_base / 'flight/brazil-airports.edgelist',
            'labels': data_base / 'flight/labels-brazil-airports.txt'
        },
        'wiki': {
            'graph': data_base / 'wiki/Wiki_edgelist.txt',
            'labels': data_base / 'wiki/wiki_labels.txt'
        },
        'lastfm': {
            'graph': data_base / 'lastfm_asia/lastfm_asia.edgelist',
            'labels': data_base / 'lastfm_asia/lastfm_asia_labels.txt'
        }
    }
    
    if dataset_name not in datasets:
        raise ValueError(f"æœªçŸ¥æ•°æ®é›†: {dataset_name}")
    
    info = datasets[dataset_name]
    
    print(f"ğŸ“‚ åŠ è½½æ•°æ®é›†: {dataset_name}")
    print(f"   å›¾æ–‡ä»¶: {info['graph']}")
    print(f"   æ ‡ç­¾æ–‡ä»¶: {info['labels']}")
    
    # åŠ è½½å›¾
    G = nx.read_edgelist(str(info['graph']), nodetype=str, create_using=nx.DiGraph())
    print(f"   å›¾ä¿¡æ¯: {G.number_of_nodes()} èŠ‚ç‚¹, {G.number_of_edges()} è¾¹")
    
    # åŠ è½½æ ‡ç­¾
    X, Y = read_node_label(str(info['labels']), skip_head=True)
    print(f"   æ ‡ç­¾ä¿¡æ¯: {len(X)} ä¸ªæ ‡è®°èŠ‚ç‚¹")
    
    return G, X, Y

def run_safe_baseline_struc2vec(G, X, Y, random_seed=42, **kwargs):
    """å®‰å…¨è¿è¡ŒåŸºçº¿Struc2Vec"""
    print("\\nğŸš€ è®­ç»ƒåŸºçº¿ Struc2Vec...")
    start = time.time()
    
    try:
        model = Struc2Vec(
            G,
            walk_length=kwargs.get('walk_length', 40),
            num_walks=kwargs.get('num_walks', 8),
            workers=kwargs.get('workers', 1),
            verbose=0,
            opt1_reduce_len=True,
            opt2_reduce_sim_calc=True
        )
        model.train(
            embed_size=kwargs.get('embed_size', 64),
            window_size=5,
            workers=kwargs.get('workers', 1),
            iter=kwargs.get('iter', 3)
        )
        embeddings = model.get_embeddings()
        training_time = time.time() - start
        
        # éªŒè¯å®éªŒè®¾ç½®
        print("ğŸ” éªŒè¯åŸºçº¿æ–¹æ³•å®éªŒè®¾ç½®...")
        DataLeakageChecker.validate_experimental_setup(embeddings, X, Y, train_ratio=0.8)
        
        # å®‰å…¨è¯„ä¼°
        result = safe_evaluate_method(embeddings, X, Y, "Baseline Struc2Vec", random_seed)
        result['training_time'] = training_time
        
        print(f"   âœ… å®Œæˆ: å‡†ç¡®ç‡={result['accuracy']:.4f}, æ—¶é—´={training_time:.2f}s")
        return result
        
    except Exception as e:
        print(f"   âŒ åŸºçº¿æ–¹æ³•å¤±è´¥: {e}")
        return {'method': 'Baseline Struc2Vec', 'success': False, 'training_time': 0, 'error': str(e)}

def run_safe_advanced_fusion_method(G, X, Y, fusion_method, random_seed=42, **kwargs):
    """å®‰å…¨è¿è¡Œé«˜çº§èåˆæ–¹æ³•"""
    print(f"\\nğŸš€ è®­ç»ƒé«˜çº§èåˆæ–¹æ³•: {fusion_method}...")
    start = time.time()
    
    try:
        # è®¾ç½®èåˆå‚æ•°
        fusion_params = {}
        if fusion_method == 'attention':
            fusion_params = {'num_heads': 4, 'feature_dim': 64}
        elif fusion_method == 'pyramid':
            fusion_params = {'pyramid_levels': 3}
        elif fusion_method == 'spectral':
            fusion_params = {'num_eigenvectors': 10}
        elif fusion_method == 'community':
            fusion_params = {'resolution': 1.0}
        
        model = AdvancedFusionStruc2Vec(
            G,
            fusion_method=fusion_method,
            fusion_params=fusion_params,
            walk_length=kwargs.get('walk_length', 40),
            num_walks=kwargs.get('num_walks', 8),
            workers=kwargs.get('workers', 1),
            verbose=0,
            max_layer=kwargs.get('max_layer', 3),
            distance_method=kwargs.get('distance_method', 'frobenius'),
            use_orbit_selection=False
        )
        
        model.train(
            embed_size=kwargs.get('embed_size', 64),
            window_size=5,
            workers=kwargs.get('workers', 1),
            iter=kwargs.get('iter', 3)
        )
        embeddings = model.get_embeddings()
        training_time = time.time() - start
        
        # éªŒè¯å®éªŒè®¾ç½®
        print(f"ğŸ” éªŒè¯ {fusion_method} æ–¹æ³•å®éªŒè®¾ç½®...")
        DataLeakageChecker.validate_experimental_setup(embeddings, X, Y, train_ratio=0.8)
        
        # å®‰å…¨è¯„ä¼°
        method_name = f"Advanced Fusion ({fusion_method})"
        result = safe_evaluate_method(embeddings, X, Y, method_name, random_seed)
        result['training_time'] = training_time
        
        print(f"   âœ… å®Œæˆ: å‡†ç¡®ç‡={result['accuracy']:.4f}, æ—¶é—´={training_time:.2f}s")
        return result
        
    except Exception as e:
        print(f"   âŒ é«˜çº§èåˆæ–¹æ³• {fusion_method} å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return {
            'method': f'Advanced Fusion ({fusion_method})', 
            'success': False, 
            'training_time': 0, 
            'error': str(e)
        }

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='å®‰å…¨çš„é«˜çº§èåˆæ–¹æ³•æ¯”è¾ƒ')
    parser.add_argument('--dataset', default='brazil-airports', 
                       choices=['brazil-airports', 'wiki', 'lastfm'])
    parser.add_argument('--fusion-methods', default='attention,spectral',
                       help='fusion methods to test (comma-separated)')
    parser.add_argument('--include-baseline', action='store_true', default=True,
                       help='include baseline Struc2Vec for comparison')
    parser.add_argument('--random-seed', type=int, default=42,
                       help='random seed for reproducible results')
    parser.add_argument('--num-walks', type=int, default=4)
    parser.add_argument('--walk-length', type=int, default=20)
    parser.add_argument('--embed-size', type=int, default=64)
    parser.add_argument('--iter', type=int, default=2)
    parser.add_argument('--workers', type=int, default=1)
    parser.add_argument('--max-layer', type=int, default=3)
    parser.add_argument('--distance-method', default='frobenius',
                       choices=['frobenius', 'eigenvalue', 'trace'])
    
    args = parser.parse_args()
    
    print("=" * 80)
    print("ğŸ›¡ï¸  å®‰å…¨çš„é«˜çº§èåˆæ–¹æ³•æ¯”è¾ƒ (Data Leakage Prevention)")
    print("=" * 80)
    print(f"æ•°æ®é›†: {args.dataset}")
    print(f"èåˆæ–¹æ³•: {args.fusion_methods}")
    print(f"åŒ…å«åŸºçº¿: {args.include_baseline}")
    print(f"éšæœºç§å­: {args.random_seed} (ç¡®ä¿å¯é‡å¤æ€§)")
    
    try:
        # åŠ è½½æ•°æ®
        G, X, Y = load_dataset(args.dataset)
        
        # æ•°æ®æ³„éœ²é¢„æ£€æŸ¥
        print("\\nğŸ” æ•°æ®æ³„éœ²é¢„æ£€æŸ¥...")
        print(f"   å›¾èŠ‚ç‚¹æ•°: {G.number_of_nodes()}")
        print(f"   æ ‡è®°èŠ‚ç‚¹æ•°: {len(X)}")
        print(f"   æ ‡è®°èŠ‚ç‚¹åœ¨å›¾ä¸­çš„æ¯”ä¾‹: {len(X)/G.number_of_nodes():.1%}")
        
        # æ£€æŸ¥æ ‡è®°èŠ‚ç‚¹æ˜¯å¦éƒ½åœ¨å›¾ä¸­
        graph_nodes = set(G.nodes())
        label_nodes = set(X)
        missing_nodes = label_nodes - graph_nodes
        if missing_nodes:
            print(f"âš ï¸  è­¦å‘Š: {len(missing_nodes)} ä¸ªæ ‡è®°èŠ‚ç‚¹ä¸åœ¨å›¾ä¸­")
        else:
            print("âœ… æ‰€æœ‰æ ‡è®°èŠ‚ç‚¹éƒ½åœ¨å›¾ä¸­")
        
        # è¿è¡Œç®—æ³•
        fusion_methods = [m.strip() for m in args.fusion_methods.split(',')]
        results = []
        
        common_params = {
            'walk_length': args.walk_length,
            'num_walks': args.num_walks,
            'embed_size': args.embed_size,
            'iter': args.iter,
            'workers': args.workers,
            'max_layer': args.max_layer,
            'distance_method': args.distance_method
        }
        
        # åŸºçº¿æ–¹æ³•
        if args.include_baseline:
            baseline_result = run_safe_baseline_struc2vec(
                G, X, Y, random_seed=args.random_seed, **common_params
            )
            results.append(baseline_result)
        
        # é«˜çº§èåˆæ–¹æ³•
        for fusion_method in fusion_methods:
            if fusion_method in ['attention', 'pyramid', 'spectral', 'community', 'ensemble']:
                result = run_safe_advanced_fusion_method(
                    G, X, Y, fusion_method, random_seed=args.random_seed, **common_params
                )
                results.append(result)
            else:
                print(f"âš ï¸  è·³è¿‡æœªçŸ¥èåˆæ–¹æ³•: {fusion_method}")
        
        # æ‰“å°ç»“æœ
        print("\\n" + "=" * 80)
        print("ğŸ“Š å®‰å…¨æ¯”è¾ƒç»“æœ (æ— æ•°æ®æ³„éœ²)")
        print("=" * 80)
        
        print(f"\\n{'æ–¹æ³•':<30} {'æˆåŠŸ':<6} {'å‡†ç¡®ç‡':<10} {'F1-Micro':<10} {'F1-Macro':<10} {'è®­ç»ƒé›†':<8} {'æµ‹è¯•é›†':<8} {'æ—¶é—´(s)':<10}")
        print("-" * 110)
        
        successful_results = []
        for result in results:
            status = "âœ…" if result.get('success', False) else "âŒ"
            accuracy = result.get('accuracy', 0)
            f1_micro = result.get('f1_micro', 0)
            f1_macro = result.get('f1_macro', 0)
            train_size = result.get('train_size', 0)
            test_size = result.get('test_size', 0)
            time_taken = result.get('training_time', 0)
            
            print(f"{result['method']:<30} {status:<6} {accuracy:<10.4f} {f1_micro:<10.4f} {f1_macro:<10.4f} {train_size:<8} {test_size:<8} {time_taken:<10.2f}")
            
            if result.get('success', False):
                successful_results.append(result)
            elif 'error' in result:
                print(f"      é”™è¯¯: {result['error'][:50]}...")
        
        # æ•°æ®å®Œæ•´æ€§æœ€ç»ˆæ£€æŸ¥
        print("\\nğŸ” æœ€ç»ˆæ•°æ®å®Œæ•´æ€§æ£€æŸ¥:")
        for result in successful_results:
            train_size = result.get('train_size', 0)
            test_size = result.get('test_size', 0)
            total_eval = train_size + test_size
            print(f"   {result['method']}: è®­ç»ƒé›†={train_size}, æµ‹è¯•é›†={test_size}, æ€»è®¡={total_eval}, æœŸæœ›={len(X)}")
            
            if total_eval != len(X):
                print(f"   âš ï¸  æ•°æ®ä¸ä¸€è‡´: {result['method']}")
        
        # æ€§èƒ½åˆ†æ
        if successful_results:
            print("\\n" + "=" * 80)
            print("ğŸ“ˆ æ€§èƒ½åˆ†æ (å¯ä¿¡ç»“æœ)")
            print("=" * 80)
            
            # æ‰¾åˆ°æœ€ä½³æ–¹æ³•
            best_result = max(successful_results, key=lambda x: x['accuracy'])
            print(f"\\nğŸ† æœ€ä½³æ–¹æ³•: {best_result['method']}")
            print(f"ğŸ† æœ€ä½³å‡†ç¡®ç‡: {best_result['accuracy']:.4f}")
            print(f"ğŸ† è®­ç»ƒé›†å¤§å°: {best_result.get('train_size', 'N/A')}")
            print(f"ğŸ† æµ‹è¯•é›†å¤§å°: {best_result.get('test_size', 'N/A')}")
            
            # ä¸åŸºçº¿æ¯”è¾ƒ
            baseline_results = [r for r in successful_results if 'Baseline' in r['method']]
            if baseline_results:
                baseline = baseline_results[0]
                print(f"\\nğŸ“Š ç›¸å¯¹åŸºçº¿ Struc2Vec çš„æ”¹è¿›:")
                
                for result in successful_results:
                    if 'Baseline' not in result['method']:
                        if baseline['accuracy'] > 0:
                            acc_improvement = (result['accuracy'] - baseline['accuracy']) / baseline['accuracy'] * 100
                            time_ratio = result['training_time'] / baseline['training_time'] if baseline['training_time'] > 0 else 0
                            
                            emoji = "ğŸ“ˆ" if acc_improvement > 0 else "ğŸ“‰"
                            print(f"   {emoji} {result['method']}: å‡†ç¡®ç‡ {acc_improvement:+.1f}%, æ—¶é—´æ¯” {time_ratio:.1f}x")
            
            # å¯é‡å¤æ€§æŠ¥å‘Š
            print(f"\\nğŸ”¬ å¯é‡å¤æ€§æŠ¥å‘Š:")
            print(f"   éšæœºç§å­: {args.random_seed}")
            print(f"   æ‰€æœ‰ç»“æœåŸºäºç›¸åŒçš„è®­ç»ƒ-æµ‹è¯•åˆ†å‰²")
            print(f"   ä¸¥æ ¼é˜²æ­¢æ•°æ®æ³„éœ²")
            print(f"   å®éªŒå‚æ•°: walks={args.num_walks}, length={args.walk_length}, iter={args.iter}")
        
        print("\\nâœ… å®‰å…¨æ¯”è¾ƒå®Œæˆ! æ— æ•°æ®æ³„éœ²é£é™©")
        
    except Exception as e:
        print(f"\\nâŒ è¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())