#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•éšæœºç§å­å¯¹ç»“æœçš„å½±å“
éªŒè¯æ•°æ®æ³„éœ²é—®é¢˜
"""
import sys
import numpy as np
from pathlib import Path

# æ·»åŠ çˆ¶é¡¹ç›®è·¯å¾„
parent_path = Path(__file__).parent.parent
sys.path.append(str(parent_path))

from GraphEmbedding.ge.classify import read_node_label, Classifier
from sklearn.linear_model import LogisticRegression

def test_seed_impact():
    """æµ‹è¯•ä¸åŒéšæœºç§å­å¯¹æ•°æ®åˆ†å‰²çš„å½±å“"""
    
    # åŠ è½½æ•°æ®
    data_base = parent_path / 'data'
    label_file = data_base / 'flight/labels-brazil-airports.txt'
    X, Y = read_node_label(str(label_file), skip_head=True)
    
    print("ğŸ§ª éšæœºç§å­å½±å“æµ‹è¯•")
    print("=" * 50)
    print(f"æ•°æ®é›†: brazil-airports")
    print(f"æ€»æ ·æœ¬æ•°: {len(X)}")
    print(f"è®­ç»ƒæ¯”ä¾‹: 80%")
    
    # æµ‹è¯•ä¸åŒç§å­çš„åˆ†å‰²ç»“æœ
    seeds = [0, 42, 123, 999]
    
    for seed in seeds:
        print(f"\\nğŸ² éšæœºç§å­: {seed}")
        
        # æ¨¡æ‹ŸåŸç‰ˆçš„åˆ†å‰²æ–¹å¼
        np.random.seed(seed)
        training_size = int(0.8 * len(X))
        shuffle_indices = np.random.permutation(np.arange(len(X)))
        
        train_indices = shuffle_indices[:training_size]
        test_indices = shuffle_indices[training_size:]
        
        X_train = [X[i] for i in train_indices]
        X_test = [X[i] for i in test_indices]
        Y_train = [Y[i] for i in train_indices]
        Y_test = [Y[i] for i in test_indices]
        
        print(f"   è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬")
        print(f"   æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬")
        print(f"   è®­ç»ƒé›†å‰3ä¸ªèŠ‚ç‚¹: {X_train[:3]}")
        print(f"   æµ‹è¯•é›†å‰3ä¸ªèŠ‚ç‚¹: {X_test[:3]}")
        
        # æ£€æŸ¥æ ‡ç­¾åˆ†å¸ƒ
        train_labels = [y[0] if isinstance(y, list) else y for y in Y_train]
        test_labels = [y[0] if isinstance(y, list) else y for y in Y_test]
        
        train_unique = set(train_labels)
        test_unique = set(test_labels)
        
        print(f"   è®­ç»ƒé›†æ ‡ç­¾ç§ç±»: {train_unique}")
        print(f"   æµ‹è¯•é›†æ ‡ç­¾ç§ç±»: {test_unique}")
        print(f"   æ ‡ç­¾é‡å : {train_unique & test_unique}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æµ‹è¯•é›†ç‹¬æœ‰çš„æ ‡ç­¾
        test_only = test_unique - train_unique
        if test_only:
            print(f"   âš ï¸  æµ‹è¯•é›†ç‹¬æœ‰æ ‡ç­¾: {test_only}")
        else:
            print(f"   âœ… æ— æµ‹è¯•é›†ç‹¬æœ‰æ ‡ç­¾")

def simulate_original_vs_safe():
    """æ¨¡æ‹ŸåŸç‰ˆå’Œå®‰å…¨ç‰ˆçš„è¯„ä¼°å·®å¼‚"""
    
    print("\\n\\nğŸ”¬ åŸç‰ˆ vs å®‰å…¨ç‰ˆ æ¨¡æ‹Ÿå¯¹æ¯”")
    print("=" * 50)
    
    # åŠ è½½æ•°æ®
    data_base = parent_path / 'data'
    label_file = data_base / 'flight/labels-brazil-airports.txt'
    X, Y = read_node_label(str(label_file), skip_head=True)
    
    # åˆ›å»ºæ¨¡æ‹ŸåµŒå…¥ï¼ˆéšæœºå‘é‡ï¼‰
    np.random.seed(12345)  # å›ºå®šåµŒå…¥ç”Ÿæˆ
    embeddings = {}
    for node in X:
        embeddings[node] = np.random.randn(64)
    
    print(f"ç”Ÿæˆäº† {len(embeddings)} ä¸ªéšæœºåµŒå…¥å‘é‡")
    
    # åŸç‰ˆæ–¹å¼ (seed=0)
    print("\\nğŸ“Š åŸç‰ˆæ–¹å¼ (seed=0):")
    try:
        clf_original = Classifier(embeddings=embeddings, clf=LogisticRegression(max_iter=1000))
        metrics_original = clf_original.split_train_evaluate(X, Y, 0.8, seed=0)
        print(f"   å‡†ç¡®ç‡: {metrics_original['acc']:.4f}")
        print(f"   F1-micro: {metrics_original['micro']:.4f}")
        print(f"   F1-macro: {metrics_original['macro']:.4f}")
    except Exception as e:
        print(f"   âŒ åŸç‰ˆè¯„ä¼°å¤±è´¥: {e}")
    
    # å®‰å…¨ç‰ˆæ–¹å¼ (seed=42)  
    print("\\nğŸ›¡ï¸  å®‰å…¨ç‰ˆæ–¹å¼ (seed=42):")
    try:
        clf_safe = Classifier(embeddings=embeddings, clf=LogisticRegression(max_iter=1000))
        metrics_safe = clf_safe.split_train_evaluate(X, Y, 0.8, seed=42)
        print(f"   å‡†ç¡®ç‡: {metrics_safe['acc']:.4f}")
        print(f"   F1-micro: {metrics_safe['micro']:.4f}")
        print(f"   F1-macro: {metrics_safe['macro']:.4f}")
    except Exception as e:
        print(f"   âŒ å®‰å…¨ç‰ˆè¯„ä¼°å¤±è´¥: {e}")
    
    # åŒç§å­å¯¹æ¯” (éƒ½ç”¨seed=42)
    print("\\nğŸ¯ åŒç§å­å¯¹æ¯” (éƒ½ç”¨seed=42):")
    try:
        clf_same = Classifier(embeddings=embeddings, clf=LogisticRegression(max_iter=1000))
        metrics_same = clf_same.split_train_evaluate(X, Y, 0.8, seed=42)
        print(f"   å‡†ç¡®ç‡: {metrics_same['acc']:.4f}")
        print(f"   F1-micro: {metrics_same['micro']:.4f}")
        print(f"   F1-macro: {metrics_same['macro']:.4f}")
        
        if abs(metrics_safe['acc'] - metrics_same['acc']) < 0.001:
            print("   âœ… ä¸å®‰å…¨ç‰ˆç»“æœä¸€è‡´ - è¯´æ˜ä¸»è¦å·®å¼‚æ¥è‡ªéšæœºç§å­")
        else:
            print("   âš ï¸  ä¸å®‰å…¨ç‰ˆç»“æœä¸ä¸€è‡´ - å¯èƒ½æœ‰å…¶ä»–å› ç´ ")
            
    except Exception as e:
        print(f"   âŒ åŒç§å­è¯„ä¼°å¤±è´¥: {e}")

def analyze_data_leakage():
    """åˆ†ææ•°æ®æ³„éœ²çš„å…·ä½“å½±å“"""
    
    print("\\n\\nğŸ•µï¸ æ•°æ®æ³„éœ²å½±å“åˆ†æ")
    print("=" * 50)
    
    # åŠ è½½æ•°æ®
    data_base = parent_path / 'data'
    label_file = data_base / 'flight/labels-brazil-airports.txt'
    X, Y = read_node_label(str(label_file), skip_head=True)
    
    print(f"åŸå§‹æ ‡ç­¾æ ¼å¼ç¤ºä¾‹:")
    for i in range(min(5, len(Y))):
        print(f"   Y[{i}] = {Y[i]} (ç±»å‹: {type(Y[i])})")
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯å¤šæ ‡ç­¾
    is_multilabel = any(isinstance(y, list) and len(y) > 1 for y in Y)
    print(f"\\næ˜¯å¦ä¸ºå¤šæ ‡ç­¾æ•°æ®: {is_multilabel}")
    
    if is_multilabel:
        print("å¤šæ ‡ç­¾ç»Ÿè®¡:")
        all_labels = []
        for y in Y:
            if isinstance(y, list):
                all_labels.extend(y)
            else:
                all_labels.append(y)
        
        unique_labels = set(all_labels)
        print(f"   æ€»æ ‡ç­¾ç§ç±»æ•°: {len(unique_labels)}")
        print(f"   æ‰€æœ‰æ ‡ç­¾: {sorted(unique_labels)}")
        
        # æ£€æŸ¥æ ‡ç­¾åˆ†å¸ƒ
        from collections import Counter
        label_counts = Counter(all_labels)
        print(f"   æ ‡ç­¾åˆ†å¸ƒ: {dict(label_counts.most_common())}")
    else:
        # å•æ ‡ç­¾ç»Ÿè®¡
        unique_labels = set(Y)
        print(f"æ ‡ç­¾ç§ç±»æ•°: {len(unique_labels)}")
        print(f"æ‰€æœ‰æ ‡ç­¾: {sorted(unique_labels)}")

if __name__ == "__main__":
    test_seed_impact()
    simulate_original_vs_safe()
    analyze_data_leakage()