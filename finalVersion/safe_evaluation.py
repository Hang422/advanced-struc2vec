#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸¥æ ¼é˜²æ­¢æ•°æ®æ³„éœ²çš„è¯„ä¼°æ¨¡å—
"""
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, f1_score
from sklearn.preprocessing import LabelEncoder
import warnings
warnings.filterwarnings('ignore')

class SafeClassifier:
    """ä¸¥æ ¼é˜²æ­¢æ•°æ®æ³„éœ²çš„åˆ†ç±»å™¨"""
    
    def __init__(self, embeddings, clf=None):
        self.embeddings = embeddings
        self.clf = clf if clf is not None else LogisticRegression(max_iter=1000)
        self.label_encoder = LabelEncoder()
    
    def safe_split_train_evaluate(self, X, Y, train_ratio=0.8, random_seed=42):
        """
        ä¸¥æ ¼çš„è®­ç»ƒæµ‹è¯•åˆ†ç¦»è¯„ä¼°
        
        Args:
            X: èŠ‚ç‚¹IDåˆ—è¡¨
            Y: èŠ‚ç‚¹æ ‡ç­¾åˆ—è¡¨ (æ¯ä¸ªèŠ‚ç‚¹å¯èƒ½æœ‰å¤šä¸ªæ ‡ç­¾)
            train_ratio: è®­ç»ƒé›†æ¯”ä¾‹
            random_seed: éšæœºç§å­
            
        Returns:
            è¯„ä¼°æŒ‡æ ‡å­—å…¸
        """
        np.random.seed(random_seed)
        
        # å¤„ç†å¤šæ ‡ç­¾æƒ…å†µ - å–ç¬¬ä¸€ä¸ªæ ‡ç­¾ä½œä¸ºä¸»è¦æ ‡ç­¾
        Y_single = [labels[0] if isinstance(labels, list) and len(labels) > 0 else labels for labels in Y]
        
        # éšæœºæ‰“ä¹±æ•°æ®
        indices = np.random.permutation(len(X))
        train_size = int(len(X) * train_ratio)
        
        # ä¸¥æ ¼åˆ†ç¦»è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        train_indices = indices[:train_size]
        test_indices = indices[train_size:]
        
        X_train = [X[i] for i in train_indices]
        Y_train = [Y_single[i] for i in train_indices]
        X_test = [X[i] for i in test_indices]
        Y_test = [Y_single[i] for i in test_indices]
        
        # åªä½¿ç”¨è®­ç»ƒé›†çš„æ ‡ç­¾æ¥fit label encoder
        self.label_encoder.fit(Y_train)
        
        # æ£€æŸ¥æµ‹è¯•é›†æ˜¯å¦æœ‰æ–°æ ‡ç­¾
        unique_test_labels = set(Y_test)
        unique_train_labels = set(Y_train)
        unknown_labels = unique_test_labels - unique_train_labels
        
        if unknown_labels:
            print(f"âš ï¸  è­¦å‘Š: æµ‹è¯•é›†åŒ…å«è®­ç»ƒé›†ä¸­æœªè§è¿‡çš„æ ‡ç­¾: {unknown_labels}")
            # è¿‡æ»¤æ‰æœªçŸ¥æ ‡ç­¾çš„æµ‹è¯•æ ·æœ¬
            filtered_test = [(x, y) for x, y in zip(X_test, Y_test) if y in unique_train_labels]
            if len(filtered_test) == 0:
                return {'acc': 0.0, 'micro': 0.0, 'macro': 0.0, 'error': 'No valid test samples'}
            X_test, Y_test = zip(*filtered_test)
            X_test, Y_test = list(X_test), list(Y_test)
        
        # è½¬æ¢æ ‡ç­¾ä¸ºæ•°å€¼
        Y_train_encoded = self.label_encoder.transform(Y_train)
        Y_test_encoded = self.label_encoder.transform(Y_test)
        
        # æå–åµŒå…¥ç‰¹å¾ - åªä½¿ç”¨è®­ç»ƒ/æµ‹è¯•èŠ‚ç‚¹çš„åµŒå…¥
        try:
            X_train_embeddings = np.array([self.embeddings[node] for node in X_train])
            X_test_embeddings = np.array([self.embeddings[node] for node in X_test])
        except KeyError as e:
            return {'acc': 0.0, 'micro': 0.0, 'macro': 0.0, 'error': f'Missing embedding for node: {e}'}
        
        # è®­ç»ƒåˆ†ç±»å™¨ - åªä½¿ç”¨è®­ç»ƒæ•°æ®
        self.clf.fit(X_train_embeddings, Y_train_encoded)
        
        # åœ¨æµ‹è¯•é›†ä¸Šé¢„æµ‹
        Y_pred = self.clf.predict(X_test_embeddings)
        
        # è®¡ç®—æŒ‡æ ‡
        try:
            accuracy = accuracy_score(Y_test_encoded, Y_pred)
            f1_micro = f1_score(Y_test_encoded, Y_pred, average='micro')
            f1_macro = f1_score(Y_test_encoded, Y_pred, average='macro')
            
            return {
                'acc': accuracy,
                'micro': f1_micro,
                'macro': f1_macro,
                'train_size': len(X_train),
                'test_size': len(X_test),
                'num_classes': len(unique_train_labels)
            }
        except Exception as e:
            return {'acc': 0.0, 'micro': 0.0, 'macro': 0.0, 'error': str(e)}

def safe_evaluate_method(embeddings, X, Y, method_name, random_seed=42):
    """
    å®‰å…¨çš„æ–¹æ³•è¯„ä¼°å‡½æ•°
    
    Args:
        embeddings: èŠ‚ç‚¹åµŒå…¥å­—å…¸
        X: èŠ‚ç‚¹IDåˆ—è¡¨
        Y: èŠ‚ç‚¹æ ‡ç­¾åˆ—è¡¨
        method_name: æ–¹æ³•åç§°
        random_seed: éšæœºç§å­
        
    Returns:
        è¯„ä¼°ç»“æœå­—å…¸
    """
    try:
        clf = SafeClassifier(embeddings)
        metrics = clf.safe_split_train_evaluate(X, Y, train_ratio=0.8, random_seed=random_seed)
        
        if 'error' in metrics:
            print(f"   âŒ {method_name} è¯„ä¼°å¤±è´¥: {metrics['error']}")
            return {
                'method': method_name,
                'accuracy': 0.0,
                'f1_micro': 0.0,
                'f1_macro': 0.0,
                'success': False,
                'error': metrics['error']
            }
        
        result = {
            'method': method_name,
            'accuracy': metrics['acc'],
            'f1_micro': metrics['micro'],
            'f1_macro': metrics['macro'],
            'success': True,
            'train_size': metrics['train_size'],
            'test_size': metrics['test_size'],
            'num_classes': metrics['num_classes']
        }
        
        print(f"   ğŸ“Š {method_name}: å‡†ç¡®ç‡={result['accuracy']:.4f}, è®­ç»ƒé›†={metrics['train_size']}, æµ‹è¯•é›†={metrics['test_size']}")
        return result
        
    except Exception as e:
        print(f"   âŒ {method_name} è¯„ä¼°å¼‚å¸¸: {e}")
        return {
            'method': method_name,
            'accuracy': 0.0,
            'f1_micro': 0.0,
            'f1_macro': 0.0,
            'success': False,
            'error': str(e)
        }

class DataLeakageChecker:
    """æ•°æ®æ³„éœ²æ£€æŸ¥å™¨"""
    
    @staticmethod
    def check_train_test_overlap(X_train, X_test):
        """æ£€æŸ¥è®­ç»ƒé›†å’Œæµ‹è¯•é›†æ˜¯å¦æœ‰é‡å """
        train_set = set(X_train)
        test_set = set(X_test)
        overlap = train_set & test_set
        
        if overlap:
            print(f"âŒ æ•°æ®æ³„éœ²è­¦å‘Š: è®­ç»ƒé›†å’Œæµ‹è¯•é›†æœ‰ {len(overlap)} ä¸ªé‡å èŠ‚ç‚¹: {list(overlap)[:5]}...")
            return True
        else:
            print(f"âœ… æ— æ•°æ®æ³„éœ²: è®­ç»ƒé›†({len(train_set)})å’Œæµ‹è¯•é›†({len(test_set)})å®Œå…¨åˆ†ç¦»")
            return False
    
    @staticmethod
    def check_embedding_integrity(embeddings, X_all):
        """æ£€æŸ¥åµŒå…¥å®Œæ•´æ€§"""
        missing_nodes = [node for node in X_all if node not in embeddings]
        if missing_nodes:
            print(f"âš ï¸  ç¼ºå¤±åµŒå…¥çš„èŠ‚ç‚¹: {len(missing_nodes)} ä¸ª, ç¤ºä¾‹: {missing_nodes[:5]}")
            return False
        else:
            print(f"âœ… åµŒå…¥å®Œæ•´: æ‰€æœ‰ {len(X_all)} ä¸ªèŠ‚ç‚¹éƒ½æœ‰åµŒå…¥")
            return True
    
    @staticmethod
    def validate_experimental_setup(embeddings, X, Y, train_ratio=0.8):
        """éªŒè¯å®éªŒè®¾ç½®çš„åˆç†æ€§"""
        print("ğŸ” å®éªŒè®¾ç½®éªŒè¯:")
        
        # æ£€æŸ¥æ•°æ®å¤§å°
        print(f"   æ€»èŠ‚ç‚¹æ•°: {len(X)}")
        print(f"   æ€»æ ‡ç­¾æ•°: {len(Y)}")
        print(f"   è®­ç»ƒæ¯”ä¾‹: {train_ratio}")
        print(f"   é¢„æœŸè®­ç»ƒé›†å¤§å°: {int(len(X) * train_ratio)}")
        print(f"   é¢„æœŸæµ‹è¯•é›†å¤§å°: {len(X) - int(len(X) * train_ratio)}")
        
        # æ£€æŸ¥æ ‡ç­¾åˆ†å¸ƒ
        if isinstance(Y[0], list):
            all_labels = [label for labels in Y for label in labels]
        else:
            all_labels = Y
        
        unique_labels = set(all_labels)
        print(f"   å”¯ä¸€æ ‡ç­¾æ•°: {len(unique_labels)}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ ·æœ¬è¿›è¡Œæœ‰æ„ä¹‰çš„è¯„ä¼°
        min_test_size = max(len(unique_labels) * 2, 10)  # æ¯ä¸ªç±»è‡³å°‘2ä¸ªæ ·æœ¬ï¼Œæˆ–è€…è‡³å°‘10ä¸ªæ ·æœ¬
        actual_test_size = len(X) - int(len(X) * train_ratio)
        
        if actual_test_size < min_test_size:
            print(f"âš ï¸  è­¦å‘Š: æµ‹è¯•é›†å¯èƒ½å¤ªå° ({actual_test_size}) è¿›è¡Œå¯é è¯„ä¼°")
            print(f"   å»ºè®®æµ‹è¯•é›†è‡³å°‘æœ‰ {min_test_size} ä¸ªæ ·æœ¬")
        
        # æ£€æŸ¥åµŒå…¥å®Œæ•´æ€§
        DataLeakageChecker.check_embedding_integrity(embeddings, X)
        
        return True

if __name__ == "__main__":
    print("ğŸ›¡ï¸  å®‰å…¨è¯„ä¼°æ¨¡å—åŠ è½½å®Œæˆ")
    print("ä¸»è¦åŠŸèƒ½:")
    print("  - SafeClassifier: ä¸¥æ ¼é˜²æ­¢æ•°æ®æ³„éœ²çš„åˆ†ç±»å™¨")
    print("  - safe_evaluate_method: å®‰å…¨çš„æ–¹æ³•è¯„ä¼°å‡½æ•°")
    print("  - DataLeakageChecker: æ•°æ®æ³„éœ²æ£€æŸ¥å™¨")