#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nç»Ÿä¸€æµ‹è¯•è„šæœ¬ - æ¯”è¾ƒä¸åŒç®—æ³•çš„æ€§èƒ½\n\"\"\"\nimport sys\nimport argparse\nimport time\nfrom pathlib import Path\n\n# æ·»åŠ é¡¹ç›®è·¯å¾„\nproject_root = Path(__file__).parent.parent\nsys.path.append(str(project_root))\nsys.path.append(str(project_root.parent))\n\nfrom src.algorithms import OriginalStruc2Vec, GraphletStruc2Vec, FusionStruc2Vec\nfrom src.utils import DataLoader, Evaluator\nfrom config.config import ALGORITHM_CONFIG, EVALUATION_CONFIG, ensure_directories\n\ndef parse_arguments():\n    \"\"\"è§£æå‘½ä»¤è¡Œå‚æ•°\"\"\"\n    parser = argparse.ArgumentParser(description='Struc2Vec ç®—æ³•æ¯”è¾ƒå·¥å…·')\n    \n    parser.add_argument('--dataset', type=str, default='brazil-airports',\n                       choices=['brazil-airports', 'wiki', 'lastfm'],\n                       help='æ•°æ®é›†åç§°')\n    \n    parser.add_argument('--methods', type=str, default='original,graphlet,fusion',\n                       help='è¦æ¯”è¾ƒçš„æ–¹æ³•ï¼Œç”¨é€—å·åˆ†éš” (original,graphlet,fusion)')\n    \n    parser.add_argument('--fusion-alpha', type=float, default=0.5,\n                       help='èåˆæƒé‡ Î± (é»˜è®¤: 0.5)')\n    \n    parser.add_argument('--fusion-method', type=str, default='weighted',\n                       choices=['weighted', 'min', 'max'],\n                       help='èåˆæ–¹æ³• (é»˜è®¤: weighted)')\n    \n    parser.add_argument('--classifiers', type=str, default='logistic',\n                       help='åˆ†ç±»å™¨ï¼Œç”¨é€—å·åˆ†éš” (logistic,svm,rf)')\n    \n    parser.add_argument('--workers', type=int, default=2,\n                       help='å¹¶è¡Œå·¥ä½œè¿›ç¨‹æ•° (é»˜è®¤: 2)')\n    \n    parser.add_argument('--num-walks', type=int, default=8,\n                       help='éšæœºæ¸¸èµ°æ•°é‡ (é»˜è®¤: 8)')\n    \n    parser.add_argument('--walk-length', type=int, default=40,\n                       help='éšæœºæ¸¸èµ°é•¿åº¦ (é»˜è®¤: 40)')\n    \n    parser.add_argument('--embed-size', type=int, default=64,\n                       help='åµŒå…¥ç»´åº¦ (é»˜è®¤: 64)')\n    \n    parser.add_argument('--iter', type=int, default=3,\n                       help='Word2Vec è¿­ä»£æ¬¡æ•° (é»˜è®¤: 3)')\n    \n    parser.add_argument('--verbose', action='store_true',\n                       help='è¯¦ç»†è¾“å‡º')\n    \n    parser.add_argument('--save-results', action='store_true',\n                       help='ä¿å­˜ç»“æœåˆ°æ–‡ä»¶')\n    \n    return parser.parse_args()\n\ndef create_algorithms(dataset_name, graph, args):\n    \"\"\"åˆ›å»ºç®—æ³•å®ä¾‹\"\"\"\n    algorithms = []\n    methods = [m.strip() for m in args.methods.split(',')]\n    \n    # é€šç”¨å‚æ•°\n    common_params = {\n        'walk_length': args.walk_length,\n        'num_walks': args.num_walks,\n        'embed_size': args.embed_size,\n        'workers': args.workers,\n        'iter': args.iter,\n        'verbose': 1 if args.verbose else 0\n    }\n    \n    if 'original' in methods:\n        print(\"ğŸ“ åˆ›å»ºåŸå§‹ Struc2Vec ç®—æ³•...\")\n        original = OriginalStruc2Vec(graph, **common_params)\n        algorithms.append(original)\n    \n    if 'graphlet' in methods:\n        print(\"ğŸ“ åˆ›å»º Graphlet å¢å¼º Struc2Vec ç®—æ³•...\")\n        graphlet_params = common_params.copy()\n        graphlet_params.update({\n            'max_layer': 3,\n            'k': 5,\n            'distance_method': 'frobenius',\n            'use_orbit_selection': False\n        })\n        graphlet = GraphletStruc2Vec(graph, **graphlet_params)\n        algorithms.append(graphlet)\n    \n    if 'fusion' in methods:\n        print(f\"ğŸ“ åˆ›å»ºèåˆ Struc2Vec ç®—æ³• ({args.fusion_method}, Î±={args.fusion_alpha})...\")\n        fusion_params = common_params.copy()\n        fusion_params.update({\n            'alpha': args.fusion_alpha,\n            'fusion_method': args.fusion_method\n        })\n        fusion = FusionStruc2Vec(graph, **fusion_params)\n        algorithms.append(fusion)\n    \n    return algorithms\n\ndef save_results(results, args, output_path):\n    \"\"\"ä¿å­˜ç»“æœåˆ°æ–‡ä»¶\"\"\"\n    import json\n    import pickle\n    from datetime import datetime\n    \n    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n    \n    # ä¿å­˜JSONæ ¼å¼çš„ç»“æœæ‘˜è¦\n    summary = {\n        'timestamp': timestamp,\n        'dataset': args.dataset,\n        'methods': args.methods,\n        'parameters': vars(args),\n        'results_summary': results['comparison_report']\n    }\n    \n    json_file = output_path / f'comparison_results_{args.dataset}_{timestamp}.json'\n    with open(json_file, 'w', encoding='utf-8') as f:\n        json.dump(summary, f, indent=2, ensure_ascii=False)\n    \n    # ä¿å­˜å®Œæ•´çš„pickleç»“æœ\n    pickle_file = output_path / f'comparison_results_{args.dataset}_{timestamp}.pkl'\n    with open(pickle_file, 'wb') as f:\n        pickle.dump(results, f)\n    \n    print(f\"\\nğŸ’¾ ç»“æœå·²ä¿å­˜:\")\n    print(f\"   æ‘˜è¦: {json_file}\")\n    print(f\"   è¯¦ç»†: {pickle_file}\")\n\ndef main():\n    \"\"\"ä¸»å‡½æ•°\"\"\"\n    # è§£æå‚æ•°\n    args = parse_arguments()\n    \n    # ç¡®ä¿ç›®å½•å­˜åœ¨\n    ensure_directories()\n    \n    print(\"=\" * 80)\n    print(\"ğŸš€ Struc2Vec ç®—æ³•æ¯”è¾ƒå·¥å…·\")\n    print(\"=\" * 80)\n    print(f\"æ•°æ®é›†: {args.dataset}\")\n    print(f\"æ¯”è¾ƒæ–¹æ³•: {args.methods}\")\n    print(f\"åˆ†ç±»å™¨: {args.classifiers}\")\n    if 'fusion' in args.methods:\n        print(f\"èåˆå‚æ•°: {args.fusion_method}, Î±={args.fusion_alpha}\")\n    \n    start_total = time.time()\n    \n    try:\n        # åŠ è½½æ•°æ®\n        print(\"\\nğŸ“‚ åŠ è½½æ•°æ®...\")\n        loader = DataLoader()\n        graph, (X, Y) = loader.load_dataset(args.dataset)\n        \n        # åˆ›å»ºç®—æ³•\n        print(\"\\nğŸ”§ åˆ›å»ºç®—æ³•å®ä¾‹...\")\n        algorithms = create_algorithms(args.dataset, graph, args)\n        \n        if not algorithms:\n            print(\"âŒ æ²¡æœ‰æœ‰æ•ˆçš„ç®—æ³•å®ä¾‹\")\n            return\n        \n        # åˆ›å»ºè¯„ä¼°å™¨\n        classifiers = [c.strip() for c in args.classifiers.split(',')]\n        evaluator = Evaluator(\n            classifiers=classifiers,\n            train_ratio=0.8,\n            random_state=42\n        )\n        \n        # è¿è¡Œæ¯”è¾ƒ\n        print(\"\\nğŸƒ å¼€å§‹ç®—æ³•æ¯”è¾ƒ...\")\n        results = evaluator.compare_algorithms(algorithms, X, Y)\n        \n        # æ‰“å°æŠ¥å‘Š\n        evaluator.print_comparison_report(results)\n        \n        # ä¿å­˜ç»“æœ\n        if args.save_results:\n            from config.config import DATA_CONFIG\n            output_path = DATA_CONFIG['results_dir']\n            save_results(results, args, output_path)\n        \n        total_time = time.time() - start_total\n        print(f\"\\nâ±ï¸  æ€»è€—æ—¶: {total_time:.2f} ç§’\")\n        print(\"\\nâœ… æ¯”è¾ƒå®Œæˆ!\")\n        \n        # ç»™å‡ºå»ºè®®\n        report = results['comparison_report']\n        if 'best_method' in report:\n            print(f\"\\nğŸ’¡ å»ºè®®:\")\n            if report['best_accuracy'] > 0.7:\n                print(f\"   ğŸ¯ {report['best_method']} è¡¨ç°ä¼˜ç§€ (å‡†ç¡®ç‡: {report['best_accuracy']:.1%})\")\n            elif report['best_accuracy'] > 0.5:\n                print(f\"   âš ï¸  {report['best_method']} è¡¨ç°ä¸€èˆ¬ï¼Œå¯è€ƒè™‘å‚æ•°è°ƒä¼˜\")\n            else:\n                print(f\"   âŒ æ‰€æœ‰æ–¹æ³•è¡¨ç°è¾ƒå·®ï¼Œå»ºè®®æ£€æŸ¥æ•°æ®è´¨é‡æˆ–å°è¯•å…¶ä»–æ•°æ®é›†\")\n            \n            # æ•ˆç‡å»ºè®®\n            efficiency = report['efficiency_analysis']\n            fastest_method = min(efficiency.keys(), key=lambda k: efficiency[k]['training_time'])\n            if fastest_method != report['best_method']:\n                print(f\"   âš¡ å¦‚æœè¿½æ±‚é€Ÿåº¦ï¼Œæ¨è {fastest_method} (å¿« {efficiency[fastest_method]['speedup']:.1f}x)\")\n    \n    except KeyboardInterrupt:\n        print(\"\\nâš ï¸  ç”¨æˆ·ä¸­æ–­\")\n    except Exception as e:\n        print(f\"\\nâŒ è¿è¡Œå‡ºé”™: {e}\")\n        if args.verbose:\n            import traceback\n            traceback.print_exc()\n        return 1\n    \n    return 0\n\nif __name__ == \"__main__\":\n    exit(main())