#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€åŒ–çš„æ¯”è¾ƒè„šæœ¬ - åªä½¿ç”¨é€»è¾‘å›å½’è¿›è¡Œè¯„ä¼°
"""
import os
import sys
import numpy as np
import networkx as nx
import pickle
import time

# æ·»åŠ è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from GraphEmbedding.ge.classify import read_node_label, Classifier
from algorithms.traditional.struc2vec import Struc2Vec
from sklearn.linear_model import LogisticRegression


def simple_compare_methods(dataset_name="brazil-airports"):
    """ç®€å•æ¯”è¾ƒä¸åŒæ–¹æ³•çš„æ€§èƒ½ - åªä½¿ç”¨é€»è¾‘å›å½’"""
    
    # è®¾ç½®è·¯å¾„
    project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    
    if dataset_name == "brazil-airports":
        graph_path = os.path.join(project_root, "data/flight/brazil-airports.edgelist")
        label_path = os.path.join(project_root, "data/flight/labels-brazil-airports.txt")
    else:
        raise ValueError(f"æœªæ”¯æŒçš„æ•°æ®é›†: {dataset_name}")
    
    output_dir = os.path.join(project_root, "output/")
    
    print(f"{'='*80}")
    print(f"ç®€åŒ–çš„ Struc2Vec æ–¹æ³•æ¯”è¾ƒ - æ•°æ®é›†: {dataset_name}")
    print(f"{'='*80}")
    
    # åŠ è½½å›¾å’Œæ ‡ç­¾
    G = nx.read_edgelist(graph_path, create_using=nx.DiGraph(), 
                        nodetype=None, data=[('weight', int)])
    X, Y = read_node_label(label_path, skip_head=True)
    
    print(f"å›¾ä¿¡æ¯: {G.number_of_nodes()} èŠ‚ç‚¹, {G.number_of_edges()} è¾¹")
    print(f"æ ‡ç­¾ä¿¡æ¯: {len(X)} ä¸ªæ ‡è®°èŠ‚ç‚¹")
    
    results = {}
    
    # 1. åŸå§‹ struc2vec
    print(f"\n1. è®­ç»ƒåŸå§‹ struc2vec...")
    start_time = time.time()
    
    model = Struc2Vec(G, num_walks=5, walk_length=40, workers=2, verbose=0,
                     opt1_reduce_len=True, opt2_reduce_sim_calc=True)
    model.train(embed_size=64, iter=3)
    embeddings = model.get_embeddings()
    
    training_time = time.time() - start_time
    
    # è¯„ä¼°
    clf = Classifier(embeddings=embeddings, clf=LogisticRegression(max_iter=1000))
    metrics = clf.split_train_evaluate(X, Y, 0.8)
    
    results['Original'] = {
        'time': training_time,
        'accuracy': metrics['acc'],
        'f1_micro': metrics['micro'],
        'f1_macro': metrics['macro']
    }
    
    print(f"   å®Œæˆ: {training_time:.2f}ç§’, å‡†ç¡®ç‡: {metrics['acc']:.4f}")
    
    # 2. æµ‹è¯•å¯ç”¨çš„æ”¹è¿›ç‰ˆæœ¬
    improved_files = {
        'Improved_Basic': os.path.join(output_dir, f"structural_dist_improved_basic_{dataset_name}.pkl"),
        'Improved_Compact': os.path.join(output_dir, f"structural_dist_improved_compact_{dataset_name}.pkl"),
        'Improved_Frobenius': os.path.join(output_dir, f"structural_dist_improved_frobenius_{dataset_name}.pkl")
    }
    
    for method_name, dist_file in improved_files.items():
        if not os.path.exists(dist_file):
            print(f"   è·³è¿‡ {method_name}: è·ç¦»æ–‡ä»¶ä¸å­˜åœ¨")
            continue
            
        print(f"\n2. è®­ç»ƒ {method_name}...")
        start_time = time.time()
        
        model = Struc2Vec(G, num_walks=5, walk_length=40, workers=2, verbose=0,
                         opt1_reduce_len=True, opt2_reduce_sim_calc=True,
                         structural_dist_file=dist_file)
        model.train(embed_size=64, iter=3)
        embeddings = model.get_embeddings()
        
        training_time = time.time() - start_time
        
        # è¯„ä¼°
        clf = Classifier(embeddings=embeddings, clf=LogisticRegression(max_iter=1000))
        metrics = clf.split_train_evaluate(X, Y, 0.8)
        
        results[method_name] = {
            'time': training_time,
            'accuracy': metrics['acc'],
            'f1_micro': metrics['micro'],
            'f1_macro': metrics['macro']
        }
        
        print(f"   å®Œæˆ: {training_time:.2f}ç§’, å‡†ç¡®ç‡: {metrics['acc']:.4f}")
    
    # 3. ç»“æœæ¯”è¾ƒ
    print(f"\n{'='*80}")
    print("ç»“æœæ€»ç»“:")
    print(f"{'='*80}")
    
    print(f"{'æ–¹æ³•':<20} {'è®­ç»ƒæ—¶é—´':<10} {'å‡†ç¡®ç‡':<10} {'F1-Micro':<10} {'F1-Macro':<10}")
    print("-" * 70)
    
    for method, result in results.items():
        print(f"{method:<20} {result['time']:<10.2f} {result['accuracy']:<10.4f} "
              f"{result['f1_micro']:<10.4f} {result['f1_macro']:<10.4f}")
    
    # 4. æ€§èƒ½æå‡åˆ†æ
    if len(results) > 1:
        print(f"\næ€§èƒ½æå‡åˆ†æ (ç›¸æ¯”åŸå§‹æ–¹æ³•):")
        original_acc = results['Original']['accuracy']
        
        for method, result in results.items():
            if method != 'Original':
                acc_improvement = (result['accuracy'] - original_acc) / original_acc * 100
                time_ratio = result['time'] / results['Original']['time']
                print(f"  {method}: å‡†ç¡®ç‡æå‡ {acc_improvement:+.2f}%, æ—¶é—´æ¯”ä¾‹ {time_ratio:.2f}x")
    
    # 5. æ¨è
    print(f"\næ¨è:")
    if len(results) > 1:
        best_acc_method = max(results.keys(), key=lambda k: results[k]['accuracy'])
        fastest_method = min(results.keys(), key=lambda k: results[k]['time'])
        
        print(f"  æœ€ä½³å‡†ç¡®ç‡: {best_acc_method} ({results[best_acc_method]['accuracy']:.4f})")
        print(f"  æœ€å¿«è®­ç»ƒ: {fastest_method} ({results[fastest_method]['time']:.2f}ç§’)")
        
        # ç»¼åˆæ¨è
        scores = {}
        for method, result in results.items():
            # ç»¼åˆåˆ†æ•°: å‡†ç¡®ç‡æƒé‡0.7 + é€Ÿåº¦æƒé‡0.3 (é€Ÿåº¦å–å€’æ•°å¹¶å½’ä¸€åŒ–)
            max_time = max(r['time'] for r in results.values())
            speed_score = (max_time - result['time']) / max_time
            scores[method] = 0.7 * result['accuracy'] + 0.3 * speed_score
        
        best_overall = max(scores.keys(), key=lambda k: scores[k])
        print(f"  ç»¼åˆæ¨è: {best_overall} (ç»¼åˆåˆ†æ•°: {scores[best_overall]:.4f})")
    
    return results


def quick_test_single_method(method_file, dataset_name="brazil-airports"):
    """å¿«é€Ÿæµ‹è¯•å•ä¸ªæ–¹æ³•"""
    project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    
    graph_path = os.path.join(project_root, "data/flight/brazil-airports.edgelist")
    label_path = os.path.join(project_root, "data/flight/labels-brazil-airports.txt")
    
    if not os.path.exists(method_file):
        print(f"âŒ æ–¹æ³•æ–‡ä»¶ä¸å­˜åœ¨: {method_file}")
        return None
    
    print(f"ğŸš€ å¿«é€Ÿæµ‹è¯•: {os.path.basename(method_file)}")
    
    # åŠ è½½æ•°æ®
    G = nx.read_edgelist(graph_path, create_using=nx.DiGraph(), 
                        nodetype=None, data=[('weight', int)])
    X, Y = read_node_label(label_path, skip_head=True)
    
    # è®­ç»ƒ
    start_time = time.time()
    model = Struc2Vec(G, num_walks=3, walk_length=20, workers=1, verbose=0,
                     structural_dist_file=method_file)
    model.train(embed_size=32, iter=1)
    embeddings = model.get_embeddings()
    training_time = time.time() - start_time
    
    # è¯„ä¼°
    clf = Classifier(embeddings=embeddings, clf=LogisticRegression(max_iter=500))
    metrics = clf.split_train_evaluate(X, Y, 0.8)
    
    print(f"   âœ… å®Œæˆ: {training_time:.2f}ç§’, å‡†ç¡®ç‡: {metrics['acc']:.4f}")
    
    return {
        'time': training_time,
        'accuracy': metrics['acc'],
        'f1_micro': metrics['micro'],
        'f1_macro': metrics['macro']
    }


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        command = sys.argv[1]
        
        if command == "compare":
            # å®Œæ•´æ¯”è¾ƒ
            dataset = sys.argv[2] if len(sys.argv) > 2 else "brazil-airports"
            results = simple_compare_methods(dataset)
            
        elif command == "test" and len(sys.argv) > 2:
            # æµ‹è¯•å•ä¸ªæ–¹æ³•æ–‡ä»¶
            method_file = sys.argv[2]
            result = quick_test_single_method(method_file)
            
        else:
            print("ç”¨æ³•:")
            print("  python simple_compare.py compare [dataset_name]")
            print("  python simple_compare.py test [method_file_path]")
    else:
        # é»˜è®¤è¿è¡Œå®Œæ•´æ¯”è¾ƒ
        print("è¿è¡Œé»˜è®¤æ¯”è¾ƒ...")
        results = simple_compare_methods("brazil-airports")